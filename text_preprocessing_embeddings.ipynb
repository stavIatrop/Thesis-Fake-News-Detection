{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_preprocessing_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "151eUmrikh4GxGDcJnP9eow-93EOYR22P",
      "authorship_tag": "ABX9TyPM9331fbBLptlCK5Mee5xD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stavIatrop/Fake-News-Detection/blob/master/text_preprocessing_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7SFzLWfKVpP",
        "colab_type": "text"
      },
      "source": [
        "Import and split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1IRgtynKeJa",
        "colab_type": "code",
        "outputId": "3dc44247-f7bd-47b5-bfe6-87c38ad1b014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "data = pd.read_csv(\"drive/My Drive/datasets/politifact.csv\", \",\")\n",
        "data_labels = data['label'].values\n",
        "data = data['text'].values\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
        "\n",
        "for train_index, test_index in sss.split(data, data_labels):\n",
        "    X_train, X_test = data[train_index], data[test_index]\n",
        "    Y_train, Y_test = data_labels[train_index], data_labels[test_index]\n",
        "\n",
        "print(\"Train shape : \",X_train.shape)\n",
        "print(\"Test shape : \",X_test.shape)\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape :  (559,)\n",
            "Test shape :  (140,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFHIPwlLTZ0z",
        "colab_type": "text"
      },
      "source": [
        "Remove non-ascii characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoGB1DM2Kqyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_non_ascii(X):\n",
        "  for i in range(len(X)):\n",
        "    words = X[i].split()\n",
        "    filtered_list = []\n",
        "    for word in words:\n",
        "        pattern = re.compile('[^\\u0000-\\u007F]+', re.UNICODE)  #Remove all non-alphanumeric characters\n",
        "        \n",
        "        word = pattern.sub('', word)\n",
        "        filtered_list.append(word)\n",
        "        result = ' '.join(filtered_list)\n",
        "        \n",
        "    X[i] = result\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k10lmzdQJMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = remove_non_ascii(X_train)\n",
        "X_test = remove_non_ascii(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA1FfNxcT7Zl",
        "colab_type": "text"
      },
      "source": [
        "Build the training vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf4ZtC9UQmtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(sentences):     #sentences --> list of lists of tokens\n",
        "  vocab = dict()\n",
        "  for sentence in sentences:\n",
        "    for word in sentence:\n",
        "      if word in vocab.keys():\n",
        "        vocab[word] += 1\n",
        "      else:\n",
        "        vocab[word] = 1\n",
        "  return vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xrEUAD1WQPl",
        "colab_type": "code",
        "outputId": "ebea8d7a-6329-4bc1-aae8-e0cfe119d863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences = [row.split() for row in X_train]\n",
        "vocab = build_vocab(sentences)\n",
        "print({k: vocab[k] for k in list(vocab)[:10]})"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'George': 177, 'W.': 41, 'Bush': 284, 'has': 2956, 'lobbed': 3, 'thinly-veiled': 1, 'critiques': 2, 'of': 20543, 'President': 1135, 'Donald': 255}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7u85SVuWuid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def load_glove_index():\n",
        "    EMBEDDING_FILE = \"/content/drive/My Drive/GloVe/glove.6B.50d.txt\"\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:50]\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "    return embeddings_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un8SkaNkY4IW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_index = load_glove_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk4TWKtoJFvi",
        "colab_type": "text"
      },
      "source": [
        "Check the percentage that GloVe vocab covers traing vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrDMLmBqY_8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import operator\n",
        "\n",
        "def check_cover(vocab, glove_index):\n",
        "\n",
        "  not_in_embeddings = dict()\n",
        "  in_embeddings = dict()\n",
        "  text_len_in = 0\n",
        "  text_len_out = 0\n",
        "  for word in vocab.keys():\n",
        "    if word in glove_index.keys():\n",
        "      in_embeddings[word] = vocab[word]\n",
        "      text_len_in += vocab[word]\n",
        "    else:\n",
        "      not_in_embeddings[word] = vocab[word]\n",
        "      text_len_out += vocab[word]\n",
        "  \n",
        "  print(\"Training vocabulary is covered at %.2f %%\" % ((len(in_embeddings)/len(vocab)) * 100 ))\n",
        "  print(\"Training text is covered at %.2f %%\" % ((text_len_in/(text_len_in + text_len_out)) * 100) )\n",
        "  \n",
        "  not_in_emb_sorted = sorted(not_in_embeddings.items(), key=operator.itemgetter(1))[::-1]\n",
        "  \n",
        "  return not_in_emb_sorted\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T-Sl4FOZ19_",
        "colab_type": "code",
        "outputId": "7a5d4442-353d-4e9c-dba2-872a8a865c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "not_in_embeddings = check_cover(vocab=vocab, glove_index=glove_index)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training vocabulary is covered at 30.65 %\n",
            "Training text is covered at 72.05 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg_n1dE5Rait",
        "colab_type": "text"
      },
      "source": [
        "GloVe embeddings cover only ~30% of the vocabulary, which means that ~28% of our dataset is not utilized. The next step is to check the vocabulary words that are not included in the embeddings to see if we can improve things."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B5qhomDPfsF",
        "colab_type": "code",
        "outputId": "9853b866-e06d-42ef-8333-74978c58974e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "not_in_embeddings[:20]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 10424),\n",
              " ('And', 4814),\n",
              " ('The', 3134),\n",
              " ('But', 2096),\n",
              " ('We', 1938),\n",
              " (\"it's\", 1210),\n",
              " ('So', 1208),\n",
              " (\"don't\", 1152),\n",
              " ('President', 1135),\n",
              " ('You', 1104),\n",
              " ('American', 1067),\n",
              " ('United', 1010),\n",
              " ('Senator', 1006),\n",
              " (\"that's\", 1006),\n",
              " ('THE', 999),\n",
              " ('It', 971),\n",
              " ('Well,', 963),\n",
              " ('know,', 921),\n",
              " (\"we're\", 898),\n",
              " ('This', 895)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGB9SYNcXuXb",
        "colab_type": "text"
      },
      "source": [
        "It seems that many words that start with capital letter are ommited from the embeddings, but are their lower case forms ommited?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgS5xjCtZDSk",
        "colab_type": "code",
        "outputId": "b7e0fcac-a6b5-4ceb-b812-10671015ce21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'i' in glove_index"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzigmSbxSDzW",
        "colab_type": "code",
        "outputId": "8aa3fc61-a063-4af4-d06e-67158830cc02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'and' in glove_index"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2p2JoMrSc1A",
        "colab_type": "code",
        "outputId": "0ea77497-f52b-4646-e137-ff459bde5918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'the' in glove_index"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RTGTSCImg-c",
        "colab_type": "code",
        "outputId": "7531bafd-6c74-4db8-d3fc-0d41bbfb0aaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'president' in glove_index"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWTKE3VAZrFy",
        "colab_type": "text"
      },
      "source": [
        "As it was suspected, the preprocessing of the embeddings may include the process of lower casing the data. So, let's transform the data into lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVmrSTKMaXrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toLowerCase(X):\n",
        "\n",
        "  for i in range(len(X)):\n",
        "    filtered_list = []\n",
        "    for word in X[i].split():\n",
        "      word = word.lower()\n",
        "      filtered_list.append(word)\n",
        "      result = ' '.join(filtered_list)\n",
        "\n",
        "    X[i] = result\n",
        "  \n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JH4-HLOg3v9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = toLowerCase(X_train)\n",
        "sentences = [row.split() for row in X_train]\n",
        "vocab = build_vocab(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWrOfOZnhU_7",
        "colab_type": "text"
      },
      "source": [
        "Now that the text is lower case, check the coverage of embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tonA6Xokhb-8",
        "colab_type": "code",
        "outputId": "e2ef53e7-3bc6-422b-8f24-fd171bc8e3af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "not_in_embeddings = check_cover(vocab=vocab, glove_index=glove_index)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training vocabulary is covered at 44.12 %\n",
            "Training text is covered at 84.67 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GK4xZXnhuJg",
        "colab_type": "text"
      },
      "source": [
        "The coverage was increased from 30% to 44%. Let's check now for words not included in embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woIuoR8BiMaS",
        "colab_type": "code",
        "outputId": "af225c24-ac1b-440e-ba6c-055e583452b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "not_in_embeddings[:20]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"it's\", 1838),\n",
              " (\"that's\", 1635),\n",
              " (\"don't\", 1188),\n",
              " (\"we're\", 1178),\n",
              " ('well,', 1117),\n",
              " ('know,', 921),\n",
              " (\"i'm\", 848),\n",
              " ('it.', 827),\n",
              " ('now,', 806),\n",
              " (\"we've\", 748),\n",
              " ('(applause.)', 586),\n",
              " ('obama:', 577),\n",
              " ('that.', 562),\n",
              " (\"they're\", 552),\n",
              " (\"you're\", 532),\n",
              " ('that,', 493),\n",
              " ('tapper:', 487),\n",
              " (\"i've\", 485),\n",
              " (\"there's\", 480),\n",
              " ('said,', 470)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR5FYR4-ZFeC",
        "colab_type": "code",
        "outputId": "33c1abee-0a85-4cb5-a724-5ae5fc51f734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'obama' in glove_index"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QJIy3gmZKOp",
        "colab_type": "code",
        "outputId": "cad75502-df29-4f92-9f66-b0c36343e59e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'know' in glove_index"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7v934ioZNf-",
        "colab_type": "code",
        "outputId": "c60d2991-a452-4e47-d7bc-dcbb8a63adc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'thats' in glove_index"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXHR4fBLZQPT",
        "colab_type": "code",
        "outputId": "58135345-f3d5-42b7-8cd6-623adf5c3d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'dont' in glove_index"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64aaylhxmwCR",
        "colab_type": "code",
        "outputId": "425c75be-d5be-4f92-b117-93f147b37577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'theres' in glove_index"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqTyEqpwmykH",
        "colab_type": "code",
        "outputId": "b6866f73-be6c-4531-d549-c993c60055a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'\\'' in glove_index"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTf6ZJWNomSv",
        "colab_type": "code",
        "outputId": "b17df0d3-b23c-4ea8-fb2a-5f0bf54d00f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "':' in glove_index"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PfEmDn0pSZF",
        "colab_type": "code",
        "outputId": "aa9baeda-1dfa-4c21-a0a3-9d8a1d28a328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "',' in glove_index"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTs3O1glpanS",
        "colab_type": "code",
        "outputId": "b376865c-6afc-468c-a70d-211dad08420b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'(' in glove_index"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1rrEISHps45",
        "colab_type": "code",
        "outputId": "6b54d166-0b5e-461b-98d5-066c2bf84b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "').' in glove_index"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhmU5P0bpup3",
        "colab_type": "text"
      },
      "source": [
        "It seems that punctuation symbol are not totally eliminated from the preprocessing of the embeddings. So, I will remove punctuation if it is in the middle of a word token or separate it if it is at the start/end of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQB-0jrX-CpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "def handle_punctuation(X):\n",
        "\n",
        "  for i in range(len(X)):\n",
        "    filtered_list = []\n",
        "    \n",
        "    for word in X[i].split():\n",
        "      \n",
        "      cleaned = 0\n",
        "      \n",
        "      while(not cleaned):\n",
        "        punc_word = \"\"\n",
        "\n",
        "        if (word[0] in string.punctuation):\n",
        "          punc_word = word[0]\n",
        "          if (len(word) == 1):\n",
        "            cleaned = 1\n",
        "          else:\n",
        "            word = word[1:]\n",
        "          filtered_list.append(punc_word)\n",
        "          result = ' '.join(filtered_list)\n",
        "        elif (word[len(word) - 1] in string.punctuation):\n",
        "          punc_word = word[len(word) - 1]\n",
        "          word = word[:len(word) - 1]\n",
        "          filtered_list.append(punc_word)\n",
        "          result = ' '.join(filtered_list)\n",
        "        else:\n",
        "          #word = word.translate(str.maketrans(' ', ' ', string.punctuation))\n",
        "          t = str.maketrans(dict.fromkeys(string.punctuation, \" \"))\n",
        "          word = word.translate(t)\n",
        "          cleaned = 1\n",
        "          filtered_list.append(word)\n",
        "          result = ' '.join(filtered_list)\n",
        "    \n",
        "    X[i] = result\n",
        "  \n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOSrYtDy-fAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = handle_punctuation(X_train)\n",
        "sentences = [row.split() for row in X_train]\n",
        "vocab = build_vocab(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRfiw1OQBP1m",
        "colab_type": "text"
      },
      "source": [
        "Check coverage now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgUGdw6zP_Yi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "50d02668-f7e2-4a5d-d81d-e22914250d3b"
      },
      "source": [
        "not_in_embeddings = check_cover(vocab=vocab, glove_index=glove_index)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training vocabulary is covered at 92.42 %\n",
            "Training text is covered at 99.71 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt4aQNALQEqU",
        "colab_type": "text"
      },
      "source": [
        "Almost all of the text is covered! Try removing completely the punctuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpDzl2XBV3L0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(X):\n",
        "  \n",
        "  for i in range(len(X)):\n",
        "    filtered_list = []\n",
        "    for word in X[i].split():\n",
        "      \n",
        "      t = str.maketrans(dict.fromkeys(string.punctuation, \" \"))\n",
        "      word = word.translate(t)\n",
        "      filtered_list.append(word)\n",
        "      result = ' '.join(filtered_list)\n",
        "    \n",
        "    X[i] = result\n",
        "  \n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ag3ArniWHd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train = remove_punctuation(X_train)\n",
        "# sentences = [row.split() for row in X_train]\n",
        "# vocab = build_vocab(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsKMsuhOY_Y8",
        "colab_type": "text"
      },
      "source": [
        "Check coverage without punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rletLcSeZCXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "56bf4efb-9611-42a5-8568-f402ca3b747a"
      },
      "source": [
        "#not_in_embeddings = check_cover(vocab=vocab, glove_index=glove_index)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training vocabulary is covered at 92.41 %\n",
            "Training text is covered at 99.66 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6zytOkEZGlO",
        "colab_type": "text"
      },
      "source": [
        "Slightly lower (92.41%, 99.66% ), so we will keep the punctuation. And let's check for further improvement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B85gZtrQDKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "d89f8774-faeb-4956-b9f6-87209713557f"
      },
      "source": [
        "not_in_embeddings[:20]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('youve', 89),\n",
              " ('theyve', 72),\n",
              " ('shouldnt', 36),\n",
              " ('karibjanian', 34),\n",
              " ('odonnell', 29),\n",
              " ('theyll', 27),\n",
              " ('werent', 24),\n",
              " ('thinkprogress', 20),\n",
              " ('chyron', 20),\n",
              " ('guccifer', 19),\n",
              " ('abcnews', 19),\n",
              " ('whove', 19),\n",
              " ('hadn', 19),\n",
              " ('mikerin', 18),\n",
              " ('strzok', 17),\n",
              " ('antifa', 16),\n",
              " ('booo', 16),\n",
              " ('nucera', 15),\n",
              " ('isil', 13),\n",
              " ('shutterstock', 11)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYsVPiJyUpnR",
        "colab_type": "text"
      },
      "source": [
        "Many preprocessed embeddings have replaced large numbers with #, so let's clean the numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tDSFQusRWF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_numbers(X):\n",
        "  for i in range(len(X)):\n",
        "    x = X[i]\n",
        "    if bool(re.search(r'\\d', x)):\n",
        "      x = re.sub('[0-9]{4,}', ' ### ', x)\n",
        "      x = re.sub('[0-9]{3}', ' ## ', x)\n",
        "      x = re.sub('[0-9]{2}', ' # ', x)\n",
        "    X[i] = x\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRchH0dORw93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = clean_numbers(X_train)\n",
        "sentences = [row.split() for row in X_train]\n",
        "vocab = build_vocab(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNWVuiXGdRbr",
        "colab_type": "text"
      },
      "source": [
        "Check coverage with '#' instead of numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYMrSd7OcfKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c0c4b0be-296e-4438-f31c-d884e7577ae9"
      },
      "source": [
        "not_in_embeddings = check_cover(vocab=vocab, glove_index=glove_index)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training vocabulary is covered at 92.85 %\n",
            "Training text is covered at 99.73 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_N3ivhlDJtW",
        "colab_type": "text"
      },
      "source": [
        "There is an improvement of ~0.4%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu50MKJDdcMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "d1986682-c68e-4887-81a2-efc7a1669db8"
      },
      "source": [
        "not_in_embeddings[:20]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('youve', 89),\n",
              " ('theyve', 72),\n",
              " ('shouldnt', 36),\n",
              " ('karibjanian', 34),\n",
              " ('odonnell', 29),\n",
              " ('theyll', 27),\n",
              " ('werent', 24),\n",
              " ('thinkprogress', 20),\n",
              " ('chyron', 20),\n",
              " ('guccifer', 19),\n",
              " ('abcnews', 19),\n",
              " ('whove', 19),\n",
              " ('hadn', 19),\n",
              " ('mikerin', 18),\n",
              " ('strzok', 17),\n",
              " ('antifa', 16),\n",
              " ('booo', 16),\n",
              " ('nucera', 15),\n",
              " ('isil', 13),\n",
              " ('shutterstock', 11)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYOTIYWFdpgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'nt' in glove_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvBUPP9eDY-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}