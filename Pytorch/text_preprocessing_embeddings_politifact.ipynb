{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_preprocessing_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "151eUmrikh4GxGDcJnP9eow-93EOYR22P",
      "authorship_tag": "ABX9TyPzu5SFgM8ObAjPdOq4AWWK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stavIatrop/Fake-News-Detection/blob/master/text_preprocessing_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7SFzLWfKVpP",
        "colab_type": "text"
      },
      "source": [
        "Import and split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1IRgtynKeJa",
        "colab_type": "code",
        "outputId": "d1b5b30d-c98b-4183-b21d-8e2400391cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "data = pd.read_csv(\"drive/My Drive/datasets/politifact.csv\", \",\")\n",
        "data_labels = data['label'].values\n",
        "data = data['text'].values\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
        "\n",
        "for train_index, test_index in sss.split(data, data_labels):\n",
        "    X_train, X_test = data[train_index], data[test_index]\n",
        "    Y_train, Y_test = data_labels[train_index], data_labels[test_index]\n",
        "\n",
        "print(\"Train shape : \",X_train.shape)\n",
        "print(\"Test shape : \",X_test.shape)\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape :  (559,)\n",
            "Test shape :  (140,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFHIPwlLTZ0z",
        "colab_type": "text"
      },
      "source": [
        "Remove non-ascii characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoGB1DM2Kqyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_non_ascii(X):\n",
        "  for i in range(len(X)):\n",
        "    words = X[i].split()\n",
        "    filtered_list = []\n",
        "    for word in words:\n",
        "        pattern = re.compile('[^\\u0000-\\u007F]+', re.UNICODE)  #Remove all non-alphanumeric characters\n",
        "        \n",
        "        word = pattern.sub(\" \", word)\n",
        "        filtered_list.append(word)\n",
        "        result = ' '.join(filtered_list)\n",
        "        \n",
        "    X[i] = result\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k10lmzdQJMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = remove_non_ascii(X_train)\n",
        "X_test = remove_non_ascii(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA1FfNxcT7Zl",
        "colab_type": "text"
      },
      "source": [
        "Build the training vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf4ZtC9UQmtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(sentences):     #sentences --> list of lists of tokens\n",
        "  vocab = dict()\n",
        "  for sentence in sentences:\n",
        "    for word in sentence:\n",
        "      if word in vocab.keys():\n",
        "        vocab[word] += 1\n",
        "      else:\n",
        "        vocab[word] = 1\n",
        "  return vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xrEUAD1WQPl",
        "colab_type": "code",
        "outputId": "93969db3-0c16-4857-f4d2-b2c36969674e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences = [row.split() for row in X_train]\n",
        "vocab = build_vocab(sentences)\n",
        "print({k: vocab[k] for k in list(vocab)[:10]})"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'George': 177, 'W.': 41, 'Bush': 285, 'has': 2956, 'lobbed': 3, 'thinly-veiled': 1, 'critiques': 2, 'of': 20547, 'President': 1164, 'Donald': 257}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7u85SVuWuid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def load_glove_index():\n",
        "    EMBEDDING_FILE = \"/content/drive/My Drive/GloVe/glove.6B.50d.txt\"\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:50]\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "    return embeddings_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un8SkaNkY4IW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_index = load_glove_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk4TWKtoJFvi",
        "colab_type": "text"
      },
      "source": [
        "Check the percentage that GloVe vocab covers traing vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrDMLmBqY_8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import operator\n",
        "\n",
        "def check_cover(vocab, glove_index):\n",
        "\n",
        "  not_in_embeddings = dict()\n",
        "  in_embeddings = dict()\n",
        "  text_len_in = 0\n",
        "  text_len_out = 0\n",
        "  for word in vocab.keys():\n",
        "    if word in glove_index.keys():\n",
        "      in_embeddings[word] = vocab[word]\n",
        "      text_len_in += vocab[word]\n",
        "    else:\n",
        "      not_in_embeddings[word] = vocab[word]\n",
        "      text_len_out += vocab[word]\n",
        "  \n",
        "  print(\"Training vocabulary is covered at %.2f %%\" % ((len(in_embeddings)/len(vocab)) * 100 ))\n",
        "  print(\"Training text is covered at %.2f %%\" % ((text_len_in/(text_len_in + text_len_out)) * 100) )\n",
        "  \n",
        "  not_in_emb_sorted = sorted(not_in_embeddings.items(), key=operator.itemgetter(1))[::-1]\n",
        "  \n",
        "  return not_in_emb_sorted\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T-Sl4FOZ19_",
        "colab_type": "code",
        "outputId": "3e9eb3d5-749f-44f0-cfe3-5cd53928d69c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "not_in_embeddings = check_cover(vocab=vocab, glove_index=glove_index)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training vocabulary is covered at 31.06 %\n",
            "Training text is covered at 72.35 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg_n1dE5Rait",
        "colab_type": "text"
      },
      "source": [
        "GloVe embeddings cover only ~30% of the vocabulary, which means that ~28% of our dataset is not utilized. The next step is to check the vocabulary words that are not included in the embeddings to see if we can improve things."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B5qhomDPfsF",
        "colab_type": "code",
        "outputId": "95119ef6-8454-4d02-e3a0-c347b9ab36d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "not_in_embeddings[:20]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 11151),\n",
              " ('And', 4814),\n",
              " ('The', 3137),\n",
              " ('We', 2205),\n",
              " ('But', 2096),\n",
              " ('It', 1288),\n",
              " (\"it's\", 1210),\n",
              " ('So', 1209),\n",
              " ('You', 1172),\n",
              " ('President', 1164),\n",
              " (\"don't\", 1152),\n",
              " ('American', 1070),\n",
              " ('United', 1010),\n",
              " ('Senator', 1006),\n",
              " (\"that's\", 1006),\n",
              " ('THE', 999),\n",
              " ('Well,', 963),\n",
              " ('Obama', 937),\n",
              " ('know,', 921),\n",
              " ('That', 914)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGB9SYNcXuXb",
        "colab_type": "text"
      },
      "source": [
        "It seems that many words that start with capital letter are ommited from the embeddings, but are their lower case forms ommited?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgS5xjCtZDSk",
        "colab_type": "code",
        "outputId": "65b8c8e4-112b-4ce5-e778-2762bb50692b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'i' in glove_index"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzigmSbxSDzW",
        "colab_type": "code",
        "outputId": "2a7c4e3f-8cdf-4dcc-b649-e5c6779b9f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'and' in glove_index"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2p2JoMrSc1A",
        "colab_type": "code",
        "outputId": "ea9312ae-2508-4ea1-ba85-fc8fb21170ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'the' in glove_index"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RTGTSCImg-c",
        "colab_type": "code",
        "outputId": "b61f7bf0-1f86-4645-cb6c-da70f123ac43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'president' in glove_index"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWTKE3VAZrFy",
        "colab_type": "text"
      },
      "source": [
        "As it was suspected, the preprocessing of the embeddings may include the process of lower casing the data. So, let's transform the data into lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVmrSTKMaXrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toLowerCase(X):\n",
        "\n",
        "  for i in range(len(X)):\n",
        "    filtered_list = []\n",
        "    for word in X[i].split():\n",
        "      word = word.lower()\n",
        "      filtered_list.append(word)\n",
        "      result = ' '.join(filtered_list)\n",
        "\n",
        "    X[i] = result\n",
        "  \n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JH4-HLOg3v9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = toLowerCase(X_train)\n",
        "sentences = [row.split() for row in X_train]\n",
        "vocab = build_vocab(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWrOfOZnhU_7",
        "colab_type": "text"
      },
      "source": [
        "Now that the text is lower case, check the coverage of embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tonA6Xokhb-8",
        "colab_type": "code",
        "outputId": "9f5e5007-b587-460a-9b11-c345b872a5ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "not_in_embeddings = check_cover(vocab=vocab, glove_index=glove_index)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training vocabulary is covered at 44.47 %\n",
            "Training text is covered at 84.92 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GK4xZXnhuJg",
        "colab_type": "text"
      },
      "source": [
        "The coverage was increased from 31% to 44%. Let's check now for words not included in embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woIuoR8BiMaS",
        "colab_type": "code",
        "outputId": "0aac5e51-4e6d-4481-d481-b841d3ee3d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "not_in_embeddings[:20]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"it's\", 1838),\n",
              " (\"that's\", 1635),\n",
              " (\"don't\", 1188),\n",
              " (\"we're\", 1178),\n",
              " ('well,', 1117),\n",
              " ('know,', 921),\n",
              " (\"i'm\", 848),\n",
              " ('it.', 827),\n",
              " ('now,', 806),\n",
              " (\"we've\", 748),\n",
              " ('(applause.)', 586),\n",
              " ('obama:', 578),\n",
              " ('that.', 562),\n",
              " (\"they're\", 552),\n",
              " (\"you're\", 532),\n",
              " ('that,', 494),\n",
              " ('tapper:', 487),\n",
              " (\"i've\", 485),\n",
              " (\"there's\", 480),\n",
              " ('said,', 470)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR5FYR4-ZFeC",
        "colab_type": "code",
        "outputId": "e7778d7e-9569-4e67-b399-00e1c4b33304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'obama' in glove_index"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QJIy3gmZKOp",
        "colab_type": "code",
        "outputId": "25d7dcff-e5a1-44c1-e5de-041b86ba1a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'know' in glove_index"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7v934ioZNf-",
        "colab_type": "code",
        "outputId": "e0b80372-2dc4-4bd5-fecb-9c2fc8767a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'thats' in glove_index"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXHR4fBLZQPT",
        "colab_type": "code",
        "outputId": "627b46c7-0c0d-40b4-b7a7-0a9b7431e3a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'dont' in glove_index"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64aaylhxmwCR",
        "colab_type": "code",
        "outputId": "7c070e67-01c9-4e97-ff1a-b2e0c35610bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'theres' in glove_index"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqTyEqpwmykH",
        "colab_type": "code",
        "outputId": "c5c12aef-b795-4520-be61-f637d1e21fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'\\'' in glove_index"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTf6ZJWNomSv",
        "colab_type": "code",
        "outputId": "90951f41-87c4-4aef-e325-ef6b0ede0786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "':' in glove_index"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PfEmDn0pSZF",
        "colab_type": "code",
        "outputId": "e4baf1c6-33b4-478c-a2d4-0ca5469da2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "',' in glove_index"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTs3O1glpanS",
        "colab_type": "code",
        "outputId": "5017750f-d22b-4440-cbaa-6b91b429de8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'(' in glove_index"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1rrEISHps45",
        "colab_type": "code",
        "outputId": "b9f0eb5d-5d33-49f2-ca9f-2525c8e12fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "').' in glove_index"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhmU5P0bpup3",
        "colab_type": "text"
      },
      "source": [
        "It seems that punctuation symbol are not totally eliminated from the preprocessing of the embeddings. So, I will remove punctuation if it is in the middle of a word token or separate it if it is at the start/end of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQB-0jrX-CpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "def handle_punctuation(X):\n",
        "\n",
        "  for i in range(len(X)):\n",
        "    filtered_list = []\n",
        "    \n",
        "    for word in X[i].split():\n",
        "      \n",
        "      cleaned = 0\n",
        "      \n",
        "      while(not cleaned):\n",
        "        punc_word = \"\"\n",
        "\n",
        "        if (word[0] in string.punctuation):\n",
        "          punc_word = word[0]\n",
        "          if (len(word) == 1):\n",
        "            cleaned = 1\n",
        "          else:\n",
        "            word = word[1:]\n",
        "          filtered_list.append(punc_word)\n",
        "          result = ' '.join(filtered_list)\n",
        "        elif (word[len(word) - 1] in string.punctuation):\n",
        "          punc_word = word[len(word) - 1]\n",
        "          word = word[:len(word) - 1]\n",
        "          filtered_list.append(punc_word)\n",
        "          result = ' '.join(filtered_list)\n",
        "        else:\n",
        "          #word = word.translate(str.maketrans(' ', ' ', string.punctuation))\n",
        "          t = str.maketrans(dict.fromkeys(string.punctuation, \" \"))\n",
        "          word = word.translate(t)\n",
        "          cleaned = 1\n",
        "          filtered_list.append(word)\n",
        "          result = ' '.join(filtered_list)\n",
        "    \n",
        "    X[i] = result\n",
        "  \n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOSrYtDy-fAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train = handle_punctuation(X_train)\n",
        "# sentences = [row.split() for row in X_train]\n",
        "# vocab = build_vocab(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRfiw1OQBP1m",
        "colab_type": "text"
      },
      "source": [
        "Check coverage now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgUGdw6zP_Yi",
        "colab_type": "code",
        "outputId": "fa7f06dd-ef8b-4fdd-efaa-ab0f225279f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# not_in_embeddings = check_cover(vocab=vocab, glove_index=glove_index)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training vocabulary is covered at 94.19 %\n",
            "Training text is covered at 99.80 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt4aQNALQEqU",
        "colab_type": "text"
      },
      "source": [
        "Almost all of the text is covered! Try removing completely the punctuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpDzl2XBV3L0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(X):\n",
        "  \n",
        "  for i in range(len(X)):\n",
        "    filtered_list = []\n",
        "    for word in X[i].split():\n",
        "      \n",
        "      t = str.maketrans(dict.fromkeys(string.punctuation, \" \"))\n",
        "      word = word.translate(t)\n",
        "      filtered_list.append(word)\n",
        "      result = ' '.join(filtered_list)\n",
        "    \n",
        "    X[i] = result\n",
        "  \n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ag3ArniWHd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train = remove_punctuation(X_train)\n",
        "# sentences = [row.split() for row in X_train]\n",
        "# vocab = build_vocab(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsKMsuhOY_Y8",
        "colab_type": "text"
      },
      "source": [
        "Check coverage without punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rletLcSeZCXM",
        "colab_type": "code",
        "outputId": "4b32a8c3-5a03-4b3e-c327-9a3e3b28b263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#not_in_embeddings = check_cover(vocab=vocab, glove_index=glove_index)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training vocabulary is covered at 94.18 %\n",
            "Training text is covered at 99.77 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6zytOkEZGlO",
        "colab_type": "text"
      },
      "source": [
        "Slightly lower (94.18%, 99.77% ), so we will keep the punctuation. And let's check for further improvement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B85gZtrQDKT",
        "colab_type": "code",
        "outputId": "90506231-6ac4-40cd-dcf6-b5f44ebf6546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "not_in_embeddings[:20]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('karibjanian', 34),\n",
              " ('hadn', 28),\n",
              " ('guccifer', 22),\n",
              " ('mikerin', 21),\n",
              " ('thinkprogress', 20),\n",
              " ('chyron', 20),\n",
              " ('abcnews', 19),\n",
              " ('strzok', 18),\n",
              " ('nucera', 17),\n",
              " ('antifa', 17),\n",
              " ('booo', 16),\n",
              " ('isil', 13),\n",
              " ('shutterstock', 11),\n",
              " ('sciutto', 10),\n",
              " ('6079', 10),\n",
              " ('delawareans', 10),\n",
              " ('realdonaldtrump', 10),\n",
              " ('daca', 9),\n",
              " ('dcleaks', 9),\n",
              " ('hillaryclinton', 8)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYsVPiJyUpnR",
        "colab_type": "text"
      },
      "source": [
        "Many preprocessed embeddings have replaced large numbers with #, so let's clean the numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tDSFQusRWF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_numbers(X):\n",
        "  for i in range(len(X)):\n",
        "    x = X[i]\n",
        "    if bool(re.search(r'\\d', x)):\n",
        "      x = re.sub('[0-9]{4,}', ' ### ', x)\n",
        "      x = re.sub('[0-9]{3}', ' ## ', x)\n",
        "      x = re.sub('[0-9]{2}', ' # ', x)\n",
        "    X[i] = x\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRchH0dORw93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = clean_numbers(X_train)\n",
        "sentences = [row.split() for row in X_train]\n",
        "vocab = build_vocab(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNWVuiXGdRbr",
        "colab_type": "text"
      },
      "source": [
        "Check coverage with '#' instead of numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYMrSd7OcfKz",
        "colab_type": "code",
        "outputId": "0b6ef502-e315-4a63-f447-186812928499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "not_in_embeddings = check_cover(vocab=vocab, glove_index=glove_index)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training vocabulary is covered at 94.68 %\n",
            "Training text is covered at 99.82 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_N3ivhlDJtW",
        "colab_type": "text"
      },
      "source": [
        "There is an improvement of ~0.5%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu50MKJDdcMv",
        "colab_type": "code",
        "outputId": "1fee2ee2-9935-472f-c83d-33cac34274aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "not_in_embeddings[:20]"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('karibjanian', 34),\n",
              " ('hadn', 28),\n",
              " ('guccifer', 22),\n",
              " ('mikerin', 21),\n",
              " ('thinkprogress', 20),\n",
              " ('chyron', 20),\n",
              " ('abcnews', 19),\n",
              " ('strzok', 18),\n",
              " ('nucera', 17),\n",
              " ('antifa', 17),\n",
              " ('booo', 16),\n",
              " ('isil', 13),\n",
              " ('shutterstock', 11),\n",
              " ('sciutto', 10),\n",
              " ('6079', 10),\n",
              " ('delawareans', 10),\n",
              " ('realdonaldtrump', 10),\n",
              " ('daca', 9),\n",
              " ('dcleaks', 9),\n",
              " ('hillaryclinton', 8)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIwe9gEaJtFz",
        "colab_type": "text"
      },
      "source": [
        "Until here, the improvement increased from 30% to 94% and there is no obvious further improvement. The training data are ready."
      ]
    }
  ]
}